package com.qst.test

import org.apache.spark.SparkConf
import org.apache.spark.streaming._
import org.apache.spark.streaming.kafka._

/**
  *created by hkl
  */

object TestSparkStreaming {
  def main(args: Array[String]) {
    println("Start to run SparkStreamingKakfaWordCount")
//    val conf = new SparkConf().setMaster("local[4]").setAppName("SparkStreamingKakfaWordCount")
    val conf = new SparkConf().setAppName("SparkStreamingKakfaWordCount")
    val ssc = new StreamingContext(conf, Seconds(4))
    val topicMap=Map("test1" -> 1)
    //    zookeeper quorums server list
    val zkQuorum = "master:2181";
    //   consumer group
    val group = "hkl"
    //下面的处理方式假设topic test只有一个分区
    val lines = KafkaUtils.createStream(ssc, zkQuorum, group, topicMap).map(_._2)
//    lines.print()

    val words = lines.flatMap(_.split(" "))
    val wordCounts = words.map(x => (x,1L)).reduceByKey(_+_)
    wordCounts.print()

    ssc.start()   //Start the computation
    ssc.awaitTermination()   //Wait for the computation to termination
  }

}
